[
    {
        "title": "Vision",
        "belongs to": "Vision",
        "cases": [
            {
                "description": "We want the GraphQL API to be the primary means of interacting programmatically with GitLab. To achieve this, it needs full coverage - anything possible in the REST API should also be possible in the GraphQL API.\nTo help us meet this vision, the frontend should use GraphQL in preference to the REST API for new features. The GraphQL API is versionless .\nThere are no plans to deprecate the REST API. To reduce the technical burden of supporting two APIs in parallel, they should share implementations as much as possible."
            }
        ]
    },
    {
        "title": "How GitLab implements GraphQL",
        "belongs to": "How GitLab implements GraphQL",
        "cases": [
            {
                "description": "We use the GraphQL Ruby gem written by Robert Mosolgo . In addition, we have a subscription to GraphQL Pro . For details see GraphQL Pro subscription .\nAll GraphQL queries are directed to a single endpoint ( app/controllers/graphql_controller.rb#execute ), which is exposed as an API endpoint at `/api/graphql` ."
            }
        ]
    },
    {
        "title": "Deep Dive",
        "belongs to": "Deep Dive",
        "cases": [
            {
                "description": "In March 2019, Nick Thomas hosted a Deep Dive (GitLab team members only: `https://gitlab.com/gitlab-org/create-stage/issues/1` ) on the GitLab GraphQL API to share domain-specific knowledge with anyone who may work in this part of the codebase in the future. You can find the \nrecording on YouTube , and the slides on Google Slides and in PDF . Everything covered in this deep dive was accurate as of GitLab 11.9, and while specific details may have changed after that release, it should still serve as a good introduction."
            }
        ]
    },
    {
        "title": "GraphiQL",
        "belongs to": "GraphiQL",
        "cases": [
            {
                "description": "GraphiQL is an interactive GraphQL API explorer where you can play around with existing queries. You can access it in any GitLab environment on `https://<your-gitlab-site.com>/-/graphql-explorer` . For example, the one for GitLab.com ."
            }
        ]
    },
    {
        "title": "Reviewing merge requests with GraphQL changes",
        "belongs to": "Reviewing merge requests with GraphQL changes",
        "cases": [
            {
                "description": "The GraphQL framework has some specific gotchas to be aware of, and domain expertise is required to ensure they are satisfied.\nIf you are asked to review a merge request that modifies any GraphQL files or adds an endpoint, have a look at our GraphQL review guide ."
            }
        ]
    },
    {
        "title": "Reading GraphQL logs",
        "belongs to": "Reading GraphQL logs",
        "cases": [
            {
                "description": "See the Reading GraphQL logs guide for tips on how to inspect logs of GraphQL requests and monitor the performance of your GraphQL queries."
            }
        ]
    },
    {
        "title": "Authentication",
        "belongs to": "Authentication",
        "cases": [
            {
                "description": "Authentication happens through the `GraphqlController` , right now this uses the same authentication as the Rails application. So the session can be shared.\nIt’s also possible to add a `private_token` to the query string, or add a `HTTP_PRIVATE_TOKEN` header."
            }
        ]
    },
    {
        "title": "Limits",
        "belongs to": "Limits",
        "cases": [
            {
                "description": "Several limits apply to the GraphQL API and some of these can be overridden by developers."
            }
        ]
    },
    {
        "title": "Max page size",
        "belongs to": "Limits/Max page size",
        "cases": [
            {
                "description": "By default, connections can only return at most a maximum number of records defined in app/graphql/gitlab_schema.rb per page.\nDevelopers can specify a custom max page size when defining a connection."
            }
        ]
    },
    {
        "title": "Max complexity",
        "belongs to": "Limits/Max complexity",
        "cases": [
            {
                "description": "Complexity is explained on our client-facing API page .\nFields default to adding `1` to a query’s complexity score, but developers can specify a custom complexity when defining a field.\nThe complexity score of a query can itself be queried for ."
            }
        ]
    },
    {
        "title": "Request timeout",
        "belongs to": "Limits/Request timeout",
        "cases": [
            {
                "description": "Requests time out at 30 seconds."
            }
        ]
    },
    {
        "title": "Limit maximum field call count",
        "belongs to": "Limits/Limit maximum field call count",
        "cases": [
            {
                "description": "In some cases, you want to prevent the evaluation of a specific field on multiple parent nodes because it results in an N+1 query problem and there is no optimal solution. This should be considered an option of last resort, to be used only when methods such as lookahead to preload associations , or using batching have been considered.\nFor example:",
                "example": "# This usage is expected.\nquery {\n  project {\n    environments\n  }\n}\n\n# This usage is NOT expected.\n# It results in N+1 query problem. EnvironmentsResolver can't use GraphQL batch loader in favor of GraphQL pagination.\nquery {\n  projects {\n    nodes {\n      environments\n    }\n  }\n}\n"
            },
            {
                "description": "To prevent this, you can use the `Gitlab::Graphql::Limit::FieldCallCount` extension on the field:",
                "example": "# This allows maximum 1 call to the `environments` field. If the field is evaluated on more than one node,\n# it raises an error.\nfield :environments do\n        extension(::Gitlab::Graphql::Limit::FieldCallCount, limit: 1)\n      end\n"
            },
            {
                "description": "or you can apply the extension in a resolver class:",
                "example": "module Resolvers\n  class EnvironmentsResolver < BaseResolver\n    extension(::Gitlab::Graphql::Limit::FieldCallCount, limit: 1)\n    # ...\n  end\nend\n"
            },
            {
                "description": "When you add this limit, make sure that the affected field’s `description` is also updated accordingly. For example,",
                "example": "field :environments,\n      description: 'Environments of the project. This field can only be resolved for one project in any single request.'\n"
            }
        ]
    },
    {
        "title": "Breaking changes",
        "belongs to": "Breaking changes",
        "cases": [
            {
                "description": "The GitLab GraphQL API is versionless which means developers must familiarize themselves with our Deprecation and Removal process .\nBreaking changes are:\nRemoving or renaming a field, argument, enum value, or mutation. \nChanging the type or type name of an argument. The type of an argument is declared by the client when using variables , and a change would cause a query using the old type name to be rejected by the API. \nChanging the scalar type of a field or enum value where it results in a change to how the value serializes to JSON. For example, a change from a JSON String to a JSON Number, or a change to how a String is formatted. A change to another object type can be allowed so long as all scalar type fields of the object continue to serialize in the same way. \nRaising the complexity of a field or complexity multipliers in a resolver. \nChanging a field from being not nullable ( `null:false` ) to nullable ( `null:true` ), as discussed in Nullable fields . \nChanging an argument from being optional ( `required:false` ) to being required ( `required:true` ). \nChanging the max page size of a connection. \nLowering the global limits for query complexity and depth. \nAnything else that can result in queries hitting a limit that previously was allowed.\nSee the deprecating schema items section for how to deprecate items."
            }
        ]
    },
    {
        "title": "Breaking change exemptions",
        "belongs to": "Breaking changes/Breaking change exemptions",
        "cases": [
            {
                "description": "See the GraphQL API breaking change exemptions documentation ."
            }
        ]
    },
    {
        "title": "Global IDs",
        "belongs to": "Global IDs",
        "cases": [
            {
                "description": "The GitLab GraphQL API uses Global IDs (i.e: `\"gid://gitlab/MyObject/123\"` ) and never database primary key IDs.\nGlobal ID is a convention used for caching and fetching in client-side libraries.\nSee also:\nExposing Global IDs . \nMutation arguments . \nDeprecating Global IDs . \nCustomer-facing Global ID documentation .\nWe have a custom scalar type ( `Types::GlobalIDType` ) which should be used as the type of input and output arguments when the value is a `GlobalID` . The benefits of using this type instead of `ID` are:\nit validates that the value is a `GlobalID` \nit parses it into a `GlobalID` before passing it to user code \nit can be parameterized on the type of the object (for example, `GlobalIDType[Project]` ) which offers even better validation and security.\nConsider using this type for all new arguments and result types. Remember that it is perfectly possible to parameterize this type with a concern or a supertype, if you want to accept a wider range of objects (such as `GlobalIDType[Issuable]` vs `GlobalIDType[Issue]` )."
            }
        ]
    },
    {
        "title": "Optimizations",
        "belongs to": "Optimizations",
        "cases": [
            {
                "description": "By default, GraphQL tends to introduce N+1 problems unless you actively try to minimize them.\nFor stability and scalability, you must ensure that our queries do not suffer from N+1 performance issues.\nThe following are a list of tools to help you to optimize your GraphQL code:\nLook ahead allows you to preload data based on which fields are selected in the query. \nBatch loading allows you batch database queries together to be executed in one statement. \nBatchModelLoader is the recommended way to lookup records by ID to leverage batch loading. \nbefore_connection_authorization allows you to address N+1 problems specific to type authorization permission checks. \nLimit maximum field call count allows you to restrict how many times a field can return data where optimizations cannot be improved."
            }
        ]
    },
    {
        "title": "How to see N+1 problems in development",
        "belongs to": "How to see N+1 problems in development",
        "cases": [
            {
                "description": "N+1 problems can be discovered during development of a feature by:\nTailing `development.log` while you execute GraphQL queries that return collections of data. Bullet may help. \nObserving the performance bar if executing queries in the GitLab UI. \nAdding a request spec that asserts there are no (or limited) N+1 problems with the feature."
            }
        ]
    },
    {
        "title": "Types",
        "belongs to": "Types",
        "cases": [
            {
                "description": "We use a code-first schema, and we declare what type everything is in Ruby.\nFor example, `app/graphql/types/issue_type.rb` :",
                "example": "graphql_name 'Issue'\n\nfield :iid, GraphQL::Types::ID, null: true\nfield :title, GraphQL::Types::String, null: true\n\n# we also have a method here that we've defined, that extends `field`\nmarkdown_field :title_html, null: true\nfield :description, GraphQL::Types::String, null: true\nmarkdown_field :description_html, null: true\n"
            },
            {
                "description": "We give each type a name (in this case `Issue` ).\nThe `iid` , `title` and `description` are scalar GraphQL types. `iid` is a `GraphQL::Types::ID` , a special string type that signifies a unique ID. `title` and `description` are regular `GraphQL::Types::String` types.\nThe old scalar types `GraphQL:ID` , `GraphQL::INT_TYPE` , `GraphQL::STRING_TYPE` , `GraphQL:BOOLEAN_TYPE` , and `GraphQL::FLOAT_TYPE` are no longer allowed. Use `GraphQL::Types::ID` , `GraphQL::Types::Int` , `GraphQL::Types::String` , `GraphQL::Types::Boolean` , and `GraphQL::Types::Float` .\nWhen exposing a model through the GraphQL API, we do so by creating a new type in `app/graphql/types` . You can also declare custom GraphQL data types for scalar data types (for example `TimeType` ).\nWhen exposing properties in a type, make sure to keep the logic inside the definition as minimal as possible. Instead, consider moving any logic into a presenter:",
                "example": "class Types::MergeRequestType < BaseObject\n  present_using MergeRequestPresenter\n\n  name 'MergeRequest'\nend\n",
                "appendix": "An existing presenter could be used, but it is also possible to create a new presenter specifically for GraphQL.\nThe presenter is initialized using the object resolved by a field, and the context."
            }
        ]
    },
    {
        "title": "Nullable fields",
        "belongs to": "Types/Nullable fields",
        "cases": [
            {
                "description": "GraphQL allows fields to be “nullable” or “non-nullable”. The former means that `null` may be returned instead of a value of the specified type. In general , you should prefer using nullable fields to non-nullable ones, for the following reasons:\nIt’s common for data to switch from required to not-required, and back again \nEven when there is no prospect of a field becoming optional, it may not be available at query time \nFor instance, the `content` of a blob may need to be looked up from Gitaly \nIf the `content` is nullable, we can return a partial response, instead of failing the whole query \nChanging from a non-nullable field to a nullable field is difficult with a versionless schema\nNon-nullable fields should only be used when a field is required, very unlikely to become optional in the future, and straightforward to calculate. An example would be `id` fields.\nA non-nullable GraphQL schema field is an object type followed by the exclamation point (bang) `!` . Here’s an example from the `gitlab_schema.graphql` file:",
                "example": "  id: ProjectID!\n"
            },
            {
                "description": "Here’s an example of a non-nullable GraphQL array:",
                "example": "\n  errors: [String!]!\n",
                "appendix": "Further reading:\nGraphQL Best Practices Guide . \nGraphQL documentation on Object types and fields . \nUsing nullability in GraphQL"
            }
        ]
    },
    {
        "title": "Exposing Global IDs",
        "belongs to": "Types/Exposing Global IDs",
        "cases": [
            {
                "description": "In keeping with the GitLab use of Global IDs , always convert database primary key IDs into Global IDs when you expose them.\nAll fields named `id` are converted automatically into the object’s Global ID.\nFields that are not named `id` need to be manually converted. We can do this using Gitlab::GlobalID.build , or by calling `#to_global_id` on an object that has mixed in the `GlobalID::Identification` module.\nUsing an example from Types::Notes::DiscussionType :",
                "example": "field :reply_id, Types::GlobalIDType[Discussion]\n\ndef reply_id\n  Gitlab::GlobalId.build(object, id: object.reply_id)\nend\n"
            }
        ]
    },
    {
        "title": "Connection types",
        "belongs to": "Types/Connection types",
        "cases": [
            {
                "description": "note \nFor specifics on implementation, see Pagination implementation .\nGraphQL uses cursor based pagination to expose collections of items. This provides the clients with a lot of flexibility while also allowing the backend to use different pagination models.\nTo expose a collection of resources we can use a connection type. This wraps the array with default pagination fields. For example a query for project-pipelines could look like this:",
                "example": "query($project_path: ID!) {\n  project(fullPath: $project_path) {\n    pipelines(first: 2) {\n      pageInfo {\n        hasNextPage\n        hasPreviousPage\n      }\n      edges {\n        cursor\n        node {\n          id\n          status\n        }\n      }\n    }\n  }\n}\n"
            },
            {
                "description": "This would return the first 2 pipelines of a project and related pagination information, ordered by descending ID. The returned data would look like this:",
                "example": "{\n  \"data\": {\n    \"project\": {\n      \"pipelines\": {\n        \"pageInfo\": {\n          \"hasNextPage\": true,\n          \"hasPreviousPage\": false\n        },\n        \"edges\": [\n          {\n            \"cursor\": \"Nzc=\",\n            \"node\": {\n              \"id\": \"gid://gitlab/Pipeline/77\",\n              \"status\": \"FAILED\"\n            }\n          },\n          {\n            \"cursor\": \"Njc=\",\n            \"node\": {\n              \"id\": \"gid://gitlab/Pipeline/67\",\n              \"status\": \"FAILED\"\n            }\n          }\n        ]\n      }\n    }\n  }\n}\n"
            },
            {
                "description": "To get the next page, the cursor of the last known element could be passed:",
                "example": "query($project_path: ID!) {\n  project(fullPath: $project_path) {\n    pipelines(first: 2, after: \"Njc=\") {\n      pageInfo {\n        hasNextPage\n        hasPreviousPage\n      }\n      edges {\n        cursor\n        node {\n          id\n          status\n        }\n      }\n    }\n  }\n}\n",
                "appendix": "To ensure that we get consistent ordering, we append an ordering on the primary key, in descending order. The primary key is usually `id` , so we add `order(id::desc)` to the end of the relation. A primary key must be available on the underlying table."
            }
        ]
    },
    {
        "title": "Shortcut fields",
        "belongs to": "Types/Connection types/Shortcut fields",
        "cases": [
            {
                "description": "Sometimes it can seem straightforward to implement a “shortcut field”, having the resolver return the first of a collection if no parameters are passed. These “shortcut fields” are discouraged because they create maintenance overhead. They need to be kept in sync with their canonical field, and deprecated or modified if their canonical field changes. Use the functionality the framework provides unless there is a compelling reason to do otherwise.\nFor example, instead of `latest_pipeline` , use `pipelines(last:1)` ."
            }
        ]
    },
    {
        "title": "Page size limit",
        "belongs to": "Types/Connection types/Page size limit",
        "cases": [
            {
                "description": "By default, the API returns at most a maximum number of records defined in app/graphql/gitlab_schema.rb per page in a connection and this is also the default number of records returned per page if no limiting arguments ( `first:` or `last:` ) are provided by a client.\nThe `max_page_size` argument can be used to specify a different page size limit for a connection.\ncaution \nIt’s better to change the frontend client, or product requirements, to not need large amounts of records per page than it is to raise the `max_page_size` , as the default is set to ensure the GraphQL API remains performant.\nFor example:",
                "example": "field :tags,\n  Types::ContainerRepositoryTagType.connection_type,\n  null: true,\n  description: 'Tags of the container repository',\n  max_page_size: 20\n"
            }
        ]
    },
    {
        "title": "Field complexity",
        "belongs to": "Types/Connection types/Field complexity",
        "cases": [
            {
                "description": "The GitLab GraphQL API uses a complexity score to limit performing overly complex queries. Complexity is described in our client documentation on the topic.\nComplexity limits are defined in app/graphql/gitlab_schema.rb .\nBy default, fields add `1` to a query’s complexity score. This can be overridden by providing a custom\n \n complexity value for a field.\nDevelopers should specify higher complexity for fields that cause more work to be performed by the server to return data. Fields that represent data that can be returned with little-to-no work , for example in most cases; `id` or `title` , can be given a complexity of `0` ."
            }
        ]
    },
    {
        "title": "calls_gitaly",
        "belongs to": "Types/Connection types/calls_gitaly",
        "cases": [
            {
                "description": "Fields that have the potential to perform a Gitaly call when resolving must be marked as such by passing `calls_gitaly:true` to `field` when defining it.\nFor example:",
                "example": "field :blob, type: Types::Snippets::BlobType,\n      description: 'Snippet blob',\n      null: false,\n      calls_gitaly: true\n"
            },
            {
                "description": "This increments the complexity\n \n score of the field by `1` .\nIf a resolver calls Gitaly, it can be annotated with `BaseResolver.calls_gitaly!` . This passes `calls_gitaly:true` to any field that uses this resolver.\nFor example:",
                "example": "class BranchResolver < BaseResolver\n  type ::Types::BranchType, null: true\n  calls_gitaly!\n\n  argument name: ::GraphQL::Types::String, required: true\n\n  def resolve(name:)\n    object.branch(name)\n  end\nend\n",
                "appendix": "Then when we use it, any field that uses `BranchResolver` has the correct value for `calls_gitaly:` ."
            }
        ]
    },
    {
        "title": "Exposing permissions for a type",
        "belongs to": "Types/Connection types/Exposing permissions for a type",
        "cases": [
            {
                "description": "To expose permissions the current user has on a resource, you can call the `expose_permissions` passing in a separate type representing the permissions for the resource.\nFor example:",
                "example": "module Types\n  class MergeRequestType < BaseObject\n    expose_permissions Types::MergeRequestPermissionsType\n  end\nend\n"
            },
            {
                "description": "The permission type inherits from `BasePermissionType` which includes some helper methods, that allow exposing permissions as non-nullable booleans:",
                "example": "class MergeRequestPermissionsType < BasePermissionType\n  graphql_name 'MergeRequestPermissions'\n\n  present_using MergeRequestPresenter\n\n  abilities :admin_merge_request, :update_merge_request, :create_note\n\n  ability_field :resolve_note,\n                description: 'Indicates the user can resolve discussions on the merge request.'\n  permission_field :push_to_source_branch, method: :can_push_to_source_branch?\nend\n",
                "appendix": "`permission_field` \n: Acts the same as `graphql-ruby` ’s `field` method but setting a default description and type and making them non-nullable. These options can still be overridden by adding them as arguments. \n`ability_field` \n: Expose an ability defined in our policies. This behaves the same way as `permission_field` and the same arguments can be overridden. \n`abilities` \n: Allows exposing several abilities defined in our policies at once. The fields for these must all be non-nullable booleans with a default description."
            }
        ]
    },
    {
        "title": "Feature flags",
        "belongs to": "Feature flags",
        "cases": [
            {
                "description": "You can implement feature flags in GraphQL to toggle:\nThe return value of a field. \nThe behavior of an argument or mutation.\nThis can be done in a resolver, in the type, or even in a model method, depending on your preference and situation.\nnote \nIt’s recommended that you also mark the item as Alpha while it is behind a feature flag. This signals to consumers of the public GraphQL API that the field is not meant to be used yet. You can also change or remove Alpha items at any time without needing to deprecate them. When the flag is removed, “release” the schema item by removing its Alpha property to make it public."
            }
        ]
    },
    {
        "title": "Descriptions for feature-flagged items",
        "belongs to": "Feature flags/Descriptions for feature-flagged items",
        "cases": [
            {
                "description": "When using a feature flag to toggle the value or behavior of a schema item, the `description` of the item must:\nState that the value or behavior can be toggled by a feature flag. \nName the feature flag. \nState what the field returns, or behavior is, when the feature flag is disabled (or enabled, if more appropriate)."
            }
        ]
    },
    {
        "title": "Examples of using feature flags",
        "belongs to": "Feature flags/Examples of using feature flags",
        "cases": []
    },
    {
        "title": "Feature-flagged field",
        "belongs to": "Feature flags/Examples of using feature flags/Feature-flagged field",
        "cases": [
            {
                "description": "A field value is toggled based on the feature flag state. A common use is to return `null` if the feature flag is disabled:",
                "example": "field :foo, GraphQL::Types::String, null: true,\n      alpha: { milestone: '10.0' },\n      description: 'Some test field. Returns `null`' \\\n                   'if `my_feature_flag` feature flag is disabled.'\n\ndef foo\n  object.foo if Feature.enabled?(:my_feature_flag, object)\nend\n"
            }
        ]
    },
    {
        "title": "Feature-flagged argument",
        "belongs to": "Feature flags/Examples of using feature flags/Feature-flagged argument",
        "cases": [
            {
                "description": "An argument can be ignored, or have its value changed, based on the feature flag state. A common use is to ignore the argument when a feature flag is disabled:",
                "example": "argument :foo, type: GraphQL::Types::String, required: false,\n         alpha: { milestone: '10.0' },\n         description: 'Some test argument. Is ignored if ' \\\n                      '`my_feature_flag` feature flag is disabled.'\n\ndef resolve(args)\n  args.delete(:foo) unless Feature.enabled?(:my_feature_flag, object)\n  # ...\nend\n"
            }
        ]
    },
    {
        "title": "Feature-flagged mutation",
        "belongs to": "Feature flags/Examples of using feature flags/Feature-flagged mutation",
        "cases": [
            {
                "description": "A mutation that cannot be performed due to a feature flag state is handled as a non-recoverable mutation error . The error is returned at the top level:",
                "example": "description 'Mutates an object. Does not mutate the object if ' \\\n            '`my_feature_flag` feature flag is disabled.'\n\ndef resolve(id: )\n  object = authorized_find!(id: id)\n\n  raise_resource_not_available_error! '`my_feature_flag` feature flag is disabled.' \\\n    if Feature.disabled?(:my_feature_flag, object)\n  # ...\nend\n"
            }
        ]
    },
    {
        "title": "Deprecating schema items",
        "belongs to": "Deprecating schema items",
        "cases": [
            {
                "description": "The GitLab GraphQL API is versionless, which means we maintain backwards compatibility with older versions of the API with every change.\nRather than removing fields, arguments, enum values , or mutations , they must be deprecated instead.\nThe deprecated parts of the schema can then be removed in a future release in accordance with the GitLab deprecation process .\nTo deprecate a schema item in GraphQL:\nCreate a deprecation issue for the item. \nMark the item as deprecated in the schema.\nSee also:\nAliasing and deprecating mutations . \nMarking schema items as Alpha . \nHow to filter Kibana for queries that used deprecated fields ."
            }
        ]
    },
    {
        "title": "Create a deprecation issue",
        "belongs to": "Deprecating schema items/Create a deprecation issue",
        "cases": [
            {
                "description": "Every GraphQL deprecation should have a deprecation issue created using the\n \n Deprecations\n \n issue template to track its deprecation and removal.\nApply these two labels to the deprecation issue:\n`~GraphQL` \n`~deprecation`"
            }
        ]
    },
    {
        "title": "Mark the item as deprecated",
        "belongs to": "Deprecating schema items/Mark the item as deprecated",
        "cases": [
            {
                "description": "Fields, arguments, enum values, and mutations are deprecated using the `deprecated` property. The value of the property is a `Hash` of:\n`reason` - Reason for the deprecation. \n`milestone` - Milestone that the field was deprecated.\nExample:",
                "example": "field :token, GraphQL::Types::String, null: true,\n      deprecated: { reason: 'Login via token has been removed', milestone: '10.0' },\n      description: 'Token for login.'\n",
                "appendix": "The original `description` of the things being deprecated should be maintained, and should not be updated to mention the deprecation. Instead, the `reason` is appended to the `description` ."
            }
        ]
    },
    {
        "title": "Deprecation reason style guide",
        "belongs to": "Deprecating schema items/Mark the item as deprecated/Deprecation reason style guide",
        "cases": [
            {
                "description": "Where the reason for deprecation is due to the field, argument, or enum value being replaced, the `reason` must indicate the replacement. For example, the following is a `reason` for a replaced field:",
                "example": "Use `otherFieldName`\n"
            },
            {
                "description": "Examples:",
                "example": "field :designs, ::Types::DesignManagement::DesignCollectionType, null: true,\n      deprecated: { reason: 'Use `designCollection`', milestone: '10.0' },\n      description: 'The designs associated with this issue.',\n\nmodule Types\n  class TodoStateEnum < BaseEnum\n    value 'pending', deprecated: { reason: 'Use PENDING', milestone: '10.0' }\n    value 'done', deprecated: { reason: 'Use DONE', milestone: '10.0' }\n    value 'PENDING', value: 'pending'\n    value 'DONE', value: 'done'\n  end\nend\n",
                "appendix": "If the field, argument, or enum value being deprecated is not being replaced, a descriptive deprecation `reason` should be given."
            }
        ]
    },
    {
        "title": "Deprecate Global IDs",
        "belongs to": "Deprecating schema items/Mark the item as deprecated/Deprecate Global IDs",
        "cases": [
            {
                "description": "We use the rails/globalid gem to generate and parse Global IDs, so as such they are coupled to model names. When we rename a model, its Global ID changes.\nIf the Global ID is used as an argument type anywhere in the schema, then the Global ID change would typically constitute a breaking change.\nTo continue to support clients using the old Global ID argument, we add a deprecation to `Gitlab::GlobalId::Deprecations` .\nnote \nIf the Global ID is only \nexposed as a field then we do not need to deprecate it. We consider the change to the way a Global ID is expressed in a field to be backwards-compatible. We expect that clients don’t parse these values: they are meant to be treated as opaque tokens, and any structure in them is incidental and not to be relied on.\nExample scenario:\nThis example scenario is based on this merge request .\nA model named `PrometheusService` is to be renamed `Integrations::Prometheus` . The old model name is used to create a Global ID type that is used as an argument for a mutation:",
                "example": "# Mutations::UpdatePrometheus:\n\nargument :id, Types::GlobalIDType[::PrometheusService],\n              required: true,\n              description: \"The ID of the integration to mutate.\"\n"
            },
            {
                "description": "Clients call the mutation by passing a Global ID string that looks like `\"gid://gitlab/PrometheusService/1\"` , named as `PrometheusServiceID` , as the `input.id` argument:",
                "example": "mutation updatePrometheus($id: PrometheusServiceID!, $active: Boolean!) {\n  prometheusIntegrationUpdate(input: { id: $id, active: $active }) {\n    errors\n    integration {\n      active\n    }\n  }\n}\n"
            },
            {
                "description": "We rename the model to `Integrations::Prometheus` , and then update the codebase with the new name. When we come to update the mutation, we pass the renamed model to `Types::GlobalIDType[]` :",
                "example": "# Mutations::UpdatePrometheus:\n\nargument :id, Types::GlobalIDType[::Integrations::Prometheus],\n              required: true,\n              description: \"The ID of the integration to mutate.\"\n"
            },
            {
                "description": "This would cause a breaking change to the mutation, as the API now rejects clients who pass an `id` argument as `\"gid://gitlab/PrometheusService/1\"` , or that specify the argument type as `PrometheusServiceID` in the query signature.\nTo allow clients to continue to interact with the mutation unchanged, edit the `DEPRECATIONS` constant in `Gitlab::GlobalId::Deprecations` and add a new `Deprecation` to the array:",
                "example": "DEPRECATIONS = [\n  Gitlab::Graphql::DeprecationsBase::NameDeprecation.new(old_name: 'PrometheusService', new_name: 'Integrations::Prometheus', milestone: '14.0')\n].freeze\n"
            },
            {
                "description": "Then follow our regular deprecation process . To later remove support for the former argument style, remove the `Deprecation` :",
                "example": "DEPRECATIONS = [].freeze\n",
                "appendix": "During the deprecation period, the API accepts either of these formats for the argument value:\n`\"gid://gitlab/PrometheusService/1\"` \n`\"gid://gitlab/Integrations::Prometheus/1\"`\nThe API also accepts these types in the query signature for the argument:\n`PrometheusServiceID` \n`IntegrationsPrometheusID`\nnote \nAlthough queries that use the old type ( `PrometheusServiceID` in this example) are considered valid and executable by the API, validator tools consider them to be invalid. They are considered invalid because we are deprecating using a bespoke method outside of the @deprecated\n \n directive , so validators are not aware of the support.\nThe documentation mentions that the old Global ID style is now deprecated."
            }
        ]
    },
    {
        "title": "Mark schema items as Alpha",
        "belongs to": "Mark schema items as Alpha",
        "cases": [
            {
                "description": "You can mark GraphQL schema items (fields, arguments, enum values, and mutations) as Alpha .\nAn item marked as Alpha is exempt from the deprecation process and can be removed at any time without notice. Mark an item as Alpha when it is subject to change and not ready for public use.\nnote \nOnly mark new items as Alpha. Never mark existing items as Alpha because they’re already public.\nTo mark a schema item as Alpha, use the `alpha:` keyword. You must provide the `milestone:` that introduced the Alpha item.\nFor example:",
                "example": "field :token, GraphQL::Types::String, null: true,\n      alpha: { milestone: '10.0' },\n      description: 'Token for login.'\n"
            },
            {
                "description": "Similarly, you can also mark an entire mutation as Alpha by updating where the mutation is mounted in `app/graphql/types/mutation_type.rb` :",
                "example": "mount_mutation Mutations::Ci::JobArtifact::BulkDestroy, alpha: { milestone: '15.10' }\n",
                "appendix": "Alpha GraphQL items is a custom GitLab feature that leverages GraphQL deprecations. An Alpha item appears as deprecated in the GraphQL schema. Like all deprecated schema items, you can test an Alpha field in the interactive GraphQL explorer (GraphiQL). However, be aware that the GraphiQL autocomplete editor doesn’t suggest deprecated fields.\nThe item shows as Alpha in our generated GraphQL documentation and its GraphQL schema description."
            }
        ]
    },
    {
        "title": "Enums",
        "belongs to": "Enums",
        "cases": [
            {
                "description": "GitLab GraphQL enums are defined in `app/graphql/types` . When defining new enums, the following rules apply:\nValues must be uppercase. \nClass names must end with the string `Enum` . \nThe `graphql_name` must not contain the string `Enum` .\nFor example:",
                "example": "module Types\n  class TrafficLightStateEnum < BaseEnum\n    graphql_name 'TrafficLightState'\n    description 'State of a traffic light'\n\n    value 'RED', description: 'Drivers must stop.'\n    value 'YELLOW', description: 'Drivers must stop when it is safe to.'\n    value 'GREEN', description: 'Drivers can start or keep driving.'\n  end\nend\n"
            },
            {
                "description": "If the enum is used for a class property in Ruby that is not an uppercase string, you can provide a `value:` option that adapts the uppercase value.\nIn the following example:\nGraphQL inputs of `OPENED` are converted to `'opened'` . \nRuby values of `'opened'` are converted to `\"OPENED\"` in GraphQL responses.",
                "example": "module Types\n  class EpicStateEnum < BaseEnum\n    graphql_name 'EpicState'\n    description 'State of a GitLab epic'\n\n    value 'OPENED', value: 'opened', description: 'An open Epic.'\n    value 'CLOSED', value: 'closed', description: 'A closed Epic.'\n  end\nend\n",
                "appendix": "Enum values can be deprecated using the deprecated\n \n keyword ."
            }
        ]
    },
    {
        "title": "Defining GraphQL enums dynamically from Rails enums",
        "belongs to": "Enums/Defining GraphQL enums dynamically from Rails enums",
        "cases": [
            {
                "description": "If your GraphQL enum is backed by a Rails enum , then consider using the Rails enum to dynamically define the GraphQL enum values. Doing so binds the GraphQL enum values to the Rails enum definition, so if values are ever added to the Rails enum then the GraphQL enum automatically reflects the change.\nExample:",
                "example": "module Types\n  class IssuableSeverityEnum < BaseEnum\n    graphql_name 'IssuableSeverity'\n    description 'Incident severity'\n\n    ::IssuableSeverity.severities.each_key do |severity|\n      value severity.upcase, value: severity, description: \"#{severity.titleize} severity.\"\n    end\n  end\nend\n"
            }
        ]
    },
    {
        "title": "JSON",
        "belongs to": "JSON",
        "cases": [
            {
                "description": "When data to be returned by GraphQL is stored as JSON , we should continue to use GraphQL types whenever possible. Avoid using the `GraphQL::Types::JSON` type unless the JSON data returned is truly unstructured.\nIf the structure of the JSON data varies, but is one of a set of known possible structures, use a union . An example of the use of a union for this purpose is !30129 .\nField names can be mapped to hash data keys using the `hash_key:` keyword if needed.\nFor example, given the following JSON data:",
                "example": "{\n  \"title\": \"My chart\",\n  \"data\": [\n    { \"x\": 0, \"y\": 1 },\n    { \"x\": 1, \"y\": 1 },\n    { \"x\": 2, \"y\": 2 }\n  ]\n}\n"
            },
            {
                "description": "We can use GraphQL types like this:",
                "example": "module Types\n  class ChartType < BaseObject\n    field :title, GraphQL::Types::String, null: true, description: 'Title of the chart.'\n    field :data, [Types::ChartDatumType], null: true, description: 'Data of the chart.'\n  end\nend\n\nmodule Types\n  class ChartDatumType < BaseObject\n    field :x, GraphQL::Types::Int, null: true, description: 'X-axis value of the chart datum.'\n    field :y, GraphQL::Types::Int, null: true, description: 'Y-axis value of the chart datum.'\n  end\nend\n"
            }
        ]
    },
    {
        "title": "Descriptions",
        "belongs to": "Descriptions",
        "cases": [
            {
                "description": "All fields and arguments must have descriptions .\nA description of a field or argument is given using the `description:` keyword. For example:",
                "example": "field :id, GraphQL::Types::ID, description: 'ID of the issue.'\nfield :confidential, GraphQL::Types::Boolean, description: 'Indicates the issue is confidential.'\nfield :closed_at, Types::TimeType, description: 'Timestamp of when the issue was closed.'\n",
                "appendix": "You can view descriptions of fields and arguments in:\nThe GraphiQL explorer . \nThe static GraphQL API reference ."
            }
        ]
    },
    {
        "title": "Description style guide",
        "belongs to": "Descriptions/Description style guide",
        "cases": []
    },
    {
        "title": "Language and punctuation",
        "belongs to": "Descriptions/Description style guide/Language and punctuation",
        "cases": [
            {
                "description": "To describe fields and arguments, use `{x}ofthe{y}` where possible, where `{x}` is the item you’re describing, and `{y}` is the resource it applies to. For example:",
                "example": "ID of the issue.\n\nAuthor of the epics.\n"
            },
            {
                "description": "For arguments that sort or search, start with the appropriate verb. To indicate the specified values, for conciseness, you can use `this` instead of `thegiven` or `thespecified` . For example:",
                "example": "Sort issues by this criteria.\n",
                "appendix": "Do not start descriptions with `The` or `A` , for consistency and conciseness.\nEnd all descriptions with a period ( `.` )."
            }
        ]
    },
    {
        "title": "Booleans",
        "belongs to": "Descriptions/Description style guide/Booleans",
        "cases": [
            {
                "description": "For a boolean field ( `GraphQL::Types::Boolean` ), start with a verb that describes what it does. For example:",
                "example": "Indicates the issue is confidential.\n"
            },
            {
                "description": "If necessary, provide the default. For example:",
                "example": "Sets the issue to confidential. Default is false.\n"
            }
        ]
    },
    {
        "title": "Sort enums",
        "belongs to": "Descriptions/Description style guide/Sort enums",
        "cases": [
            {
                "description": "Enums for sorting should have the description `'Valuesforsorting{x}.'` . For example:",
                "example": "Values for sorting container repositories.\n"
            }
        ]
    },
    {
        "title": "Types::TimeType field description",
        "belongs to": "Descriptions/Description style guide/Types::TimeType field description",
        "cases": [
            {
                "description": "For `Types::TimeType` GraphQL fields, include the word `timestamp` . This lets the reader know that the format of the property is `Time` , rather than just `Date` .\nFor example:",
                "example": "field :closed_at, Types::TimeType, description: 'Timestamp of when the issue was closed.'\n"
            }
        ]
    },
    {
        "title": "copy_field_description helper",
        "belongs to": "Descriptions/Description style guide/copy_field_description helper",
        "cases": [
            {
                "description": "Sometimes we want to ensure that two descriptions are always identical. For example, to keep a type field description the same as a mutation argument when they both represent the same property.\nInstead of supplying a description, we can use the `copy_field_description` helper, passing it the type, and field name to copy the description of.\nExample:",
                "example": "argument :title, GraphQL::Types::String,\n          required: false,\n          description: copy_field_description(Types::MergeRequestType, :title)\n"
            }
        ]
    },
    {
        "title": "Documentation references",
        "belongs to": "Descriptions/Description style guide/Documentation references",
        "cases": [
            {
                "description": "Sometimes we want to refer to external URLs in our descriptions. To make this easier, and provide proper markup in the generated reference documentation, we provide a `see` property on fields. For example:",
                "example": "field :genus,\n      type: GraphQL::Types::String,\n      null: true,\n      description: 'A taxonomic genus.'\n      see: { 'Wikipedia page on genera' => 'https://wikipedia.org/wiki/Genus' }\n"
            },
            {
                "description": "This renders in our documentation as:",
                "example": "A taxonomic genus. See: [Wikipedia page on genera](https://wikipedia.org/wiki/Genus)\n",
                "appendix": "Multiple documentation references can be provided. The syntax for this property is a `HashMap` where the keys are textual descriptions, and the values are URLs."
            }
        ]
    },
    {
        "title": "Subscription tier badges",
        "belongs to": "Descriptions/Description style guide/Subscription tier badges",
        "cases": [
            {
                "description": "If a field or argument is available to higher subscription tiers than the other fields, add the tier badge inline.\nFor example:",
                "example": "description: '**(ULTIMATE ALL)** Full path of a custom template.'\n"
            }
        ]
    },
    {
        "title": "Authorization",
        "belongs to": "Authorization",
        "cases": [
            {
                "description": "See: GraphQL Authorization"
            }
        ]
    },
    {
        "title": "Resolvers",
        "belongs to": "Resolvers",
        "cases": [
            {
                "description": "We define how the application serves the response using resolvers stored in the `app/graphql/resolvers` directory. The resolver provides the actual implementation logic for retrieving the objects in question.\nTo find objects to display in a field, we can add resolvers to `app/graphql/resolvers` .\nArguments can be defined in the resolver in the same way as in a mutation. See the Arguments section.\nTo limit the amount of queries performed, we can use BatchLoader ."
            }
        ]
    },
    {
        "title": "Writing resolvers",
        "belongs to": "Resolvers/Writing resolvers",
        "cases": [
            {
                "description": "Our code should aim to be thin declarative wrappers around finders and services . You can repeat lists of arguments, or extract them to concerns. Composition is preferred over inheritance in most cases. Treat resolvers like controllers: resolvers should be a DSL that compose other application abstractions.\nFor example:",
                "example": "class PostResolver < BaseResolver\n  type Post.connection_type, null: true\n  authorize :read_blog\n  description 'Blog posts, optionally filtered by name'\n\n  argument :name, [::GraphQL::Types::String], required: false, as: :slug\n\n  alias_method :blog, :object\n\n  def resolve(**args)\n    PostFinder.new(blog, current_user, args).execute\n  end\nend\n",
                "appendix": "While you can use the same resolver class in two different places, such as in two different fields where the same object is exposed, you should never re-use resolver objects directly. Resolvers have a complex life-cycle, with authorization, readiness and resolution orchestrated by the framework, and at each stage lazy values can be returned to take advantage of batching opportunities. Never instantiate a resolver or a mutation in application code.\nInstead, the units of code reuse are much the same as in the rest of the application:\nFinders in queries to look up data. \nServices in mutations to apply operations. \nLoaders (batch-aware finders) specific to queries.\nThere is never any reason to use batching in a mutation. Mutations are executed in series, so there are no batching opportunities. All values are evaluated eagerly as soon as they are requested, so batching is unnecessary overhead. If you are writing:\nA `Mutation` , feel free to lookup objects directly. \nA `Resolver` or methods on a `BaseObject` , then you want to allow for batching."
            }
        ]
    },
    {
        "title": "Error handling",
        "belongs to": "Resolvers/Error handling",
        "cases": [
            {
                "description": "Resolvers may raise errors, which are converted to top-level errors as appropriate. All anticipated errors should be caught and transformed to an appropriate GraphQL error (see Gitlab::Graphql::Errors ). Any uncaught errors are suppressed and the client receives the message `Internalserviceerror` .\nThe one special case is permission errors. In the REST API we return `404NotFound` for any resources that the user does not have permission to access. The equivalent behavior in GraphQL is for us to return `null` for all absent or unauthorized resources. Query resolvers should not raise errors for unauthorized resources .\nThe rationale for this is that clients must not be able to distinguish between the absence of a record and the presence of one they do not have access to. To do so is a security vulnerability, because it leaks information we want to keep hidden.\nIn most cases you don’t need to worry about this - this is handled correctly by the resolver field authorization we declare with the `authorize` DSL calls. If you need to do something more custom however, remember, if you encounter an object the `current_user` does not have access to when resolving a field, then the entire field should resolve to `null` ."
            }
        ]
    },
    {
        "title": "Deriving resolvers",
        "belongs to": "Resolvers/Deriving resolvers",
        "cases": [
            {
                "description": "(including `BaseResolver.single` and `BaseResolver.last` )\nFor some use cases, we can derive resolvers from others. The main use case for this is one resolver to find all items, and another to find one specific one. For this, we supply convenience methods:\n`BaseResolver.single` , which constructs a new resolver that selects the first item. \n`BaseResolver.last` , which constructs a resolver that selects the last item.\nThe correct singular type is inferred from the collection type, so we don’t have to define the `type` here.\nBefore you make use of these methods, consider if it would be simpler to either:\nWrite another resolver that defines its own arguments. \nWrite a concern that abstracts out the query.\nUsing `BaseResolver.single` too freely is an anti-pattern. It can lead to non-sensical fields, such as a `Project.mergeRequest` field that just returns the first MR if no arguments are given. Whenever we derive a single resolver from a collection resolver, it must have more restrictive arguments.\nTo make this possible, use the `when_single` block to customize the single resolver. Every `when_single` block must:\nDefine (or re-define) at least one argument. \nMake optional filters required.\nFor example, we can do this by redefining an existing optional argument, changing its type and making it required:",
                "example": "class JobsResolver < BaseResolver\n  type JobType.connection_type, null: true\n  authorize :read_pipeline\n\n  argument :name, [::GraphQL::Types::String], required: false\n\n  when_single do\n    argument :name, ::GraphQL::Types::String, required: true\n  end\n\n  def resolve(**args)\n    JobsFinder.new(pipeline, current_user, args.compact).execute\n  end\n"
            },
            {
                "description": "Here we have a resolver for getting pipeline jobs. The `name` argument is optional when getting a list, but required when getting a single job.\nIf there are multiple arguments, and neither can be made required, we can use the block to add a ready condition:",
                "example": "class JobsResolver < BaseResolver\n  alias_method :pipeline, :object\n\n  type JobType.connection_type, null: true\n  authorize :read_pipeline\n\n  argument :name, [::GraphQL::Types::String], required: false\n  argument :id, [::Types::GlobalIDType[::Job]],\n           required: false,\n           prepare: ->(ids, ctx) { ids.map(&:model_id) }\n\n  when_single do\n    argument :name, ::GraphQL::Types::String, required: false\n    argument :id, ::Types::GlobalIDType[::Job],\n             required: false\n             prepare: ->(id, ctx) { id.model_id }\n\n    def ready?(**args)\n      raise ::Gitlab::Graphql::Errors::ArgumentError, 'Only one argument may be provided' unless args.size == 1\n    end\n  end\n\n  def resolve(**args)\n    JobsFinder.new(pipeline, current_user, args.compact).execute\n  end\n"
            },
            {
                "description": "Then we can use these resolver on fields:",
                "example": "# In PipelineType\n\nfield :jobs, resolver: JobsResolver, description: 'All jobs.'\nfield :job, resolver: JobsResolver.single, description: 'A single job.'\n"
            }
        ]
    },
    {
        "title": "Optimizing Resolvers",
        "belongs to": "Resolvers/Optimizing Resolvers",
        "cases": []
    },
    {
        "title": "Look-Ahead",
        "belongs to": "Resolvers/Optimizing Resolvers/Look-Ahead",
        "cases": [
            {
                "description": "The full query is known in advance during execution, which means we can make use of lookahead to optimize our queries, and batch load associations we know we need. Consider adding lookahead support in your resolvers to avoid `N+1` performance issues.\nTo enable support for common lookahead use-cases (pre-loading associations when child fields are requested), you can include LooksAhead . For example:",
                "example": "# Assuming a model `MyThing` with attributes `[child_attribute, other_attribute, nested]`,\n# where nested has an attribute named `included_attribute`.\nclass MyThingResolver < BaseResolver\n  include LooksAhead\n\n  # Rather than defining `resolve(**args)`, we implement: `resolve_with_lookahead(**args)`\n  def resolve_with_lookahead(**args)\n    apply_lookahead(MyThingFinder.new(current_user).execute)\n  end\n\n  # We list things that should always be preloaded:\n  # For example, if child_attribute is always needed (during authorization\n  # perhaps), then we can include it here.\n  def unconditional_includes\n    [:child_attribute]\n  end\n\n  # We list things that should be included if a certain field is selected:\n  def preloads\n    {\n        field_one: [:other_attribute],\n        field_two: [{ nested: [:included_attribute] }]\n    }\n  end\nend\n"
            },
            {
                "description": "By default, fields defined in `#preloads` are preloaded if that field is selected in the query. Occasionally, finer control may be needed to avoid preloading too much or incorrect content.\nExtending the above example, we might want to preload a different association if certain fields are requested together. This can be done by overriding `#filtered_preloads` :",
                "example": "class MyThingResolver < BaseResolver\n  # ...\n\n  def filtered_preloads\n    return [:alternate_attribute] if lookahead.selects?(:field_one) && lookahead.selects?(:field_two)\n\n    super\n  end\nend\n"
            },
            {
                "description": "The `LooksAhead` concern also provides basic support for preloading associations based on nested GraphQL field definitions. The WorkItemsResolver is a good example for this. `nested_preloads` is another method you can define to return a hash, but unlike the `preloads` method, the value for each hash key is another hash and not the list of associations to preload. So in the previous example, you could override `nested_preloads` like this:",
                "example": "class MyThingResolver < BaseResolver\n  # ...\n\n  def nested_preloads\n    {\n      root_field: {\n        nested_field1: :association_to_preload,\n        nested_field2: [:association1, :association2]\n      }\n    }\n  end\nend\n",
                "appendix": "For an example of real world use, see ResolvesMergeRequests ."
            }
        ]
    },
    {
        "title": "before_connection_authorization",
        "belongs to": "Resolvers/Optimizing Resolvers/before_connection_authorization",
        "cases": [
            {
                "description": "A `before_connection_authorization` hook can help resolvers eliminate N+1 problems that originate from type authorization permission checks.\nThe `before_connection_authorization` method receives the resolved nodes and the current user. In the block, use `ActiveRecord::Associations::Preloader` or a `Preloaders::` class to preload data for the type authorization check.\nExample:",
                "example": "class LabelsResolver < BaseResolver\n  before_connection_authorization do |labels, current_user|\n    Preloaders::LabelsPreloader.new(labels, current_user).preload_all\n  end\nend\n"
            }
        ]
    },
    {
        "title": "BatchLoading",
        "belongs to": "Resolvers/Optimizing Resolvers/BatchLoading",
        "cases": [
            {
                "description": "See GraphQL BatchLoader ."
            }
        ]
    },
    {
        "title": "Correct use of Resolver#ready?",
        "belongs to": "Resolvers/Optimizing Resolvers/Correct use of Resolver#ready?",
        "cases": [
            {
                "description": "Resolvers have two public API methods as part of the framework: `#ready?(**args)` and `#resolve(**args)` . We can use `#ready?` to perform set-up, validation, or early-return without invoking `#resolve` .\nGood reasons to use `#ready?` include:\nValidating mutually exclusive arguments. \nReturning `Relation.none` if we know before-hand that no results are possible. \nPerforming setup such as initializing instance variables (although consider lazily initialized methods for this).\nImplementations of Resolver#ready?(**args) should return `(Boolean,early_return_data)` as follows:",
                "example": "def ready?(**args)\n  [false, 'have this instead']\nend\n",
                "appendix": "For this reason, whenever you call a resolver (mainly in tests because framework abstractions Resolvers should not be considered re-usable, finders are to be preferred), remember to call the `ready?` method and check the boolean flag before calling `resolve` ! An example can be seen in our GraphqlHelpers ."
            }
        ]
    },
    {
        "title": "Negated arguments",
        "belongs to": "Resolvers/Optimizing Resolvers/Negated arguments",
        "cases": [
            {
                "description": "Negated filters can filter some resources (for example, find all issues that have the `bug` label, but don’t have the `bug2` label assigned). The `not` argument is the preferred syntax to pass negated arguments:",
                "example": "issues(labelName: \"bug\", not: {labelName: \"bug2\"}) {\n  nodes {\n    id\n    title\n  }\n}\n",
                "appendix": "To avoid duplicated argument definitions, you can place these arguments in a reusable module (or class, if the arguments are nested). Alternatively, you can consider to add a helper resolver method ."
            }
        ]
    },
    {
        "title": "Metadata",
        "belongs to": "Resolvers/Optimizing Resolvers/Metadata",
        "cases": [
            {
                "description": "When using resolvers, they can and should serve as the SSoT for field metadata. All field options (apart from the field name) can be declared on the resolver. These include:\n`type` (required - all resolvers must include a type annotation) \n`extras` \n`description` \nGitaly annotations (with `calls_gitaly!` )\nExample:",
                "example": "module Resolvers\n  MyResolver < BaseResolver\n    type Types::MyType, null: true\n    extras [:lookahead]\n    description 'Retrieve a single MyType'\n    calls_gitaly!\n  end\nend\n"
            }
        ]
    },
    {
        "title": "Pass a parent object into a child Presenter",
        "belongs to": "Resolvers/Optimizing Resolvers/Pass a parent object into a child Presenter",
        "cases": [
            {
                "description": "Sometimes you need to access the resolved query parent in a child context to compute fields. Usually the parent is only available in the `Resolver` class as `parent` .\nTo find the parent object in your `Presenter` class:\nAdd the parent object to the GraphQL `context` from your resolver’s `resolve` method:",
                "example": "  def resolve(**args)\n    context[:parent_object] = parent\n  end\n"
            },
            {
                "description": "Declare that your resolver or fields require the `parent` field context. For example:",
                "example": "  # in ChildType\n  field :computed_field, SomeType, null: true,\n        method: :my_computing_method,\n        extras: [:parent], # Necessary\n        description: 'My field description.'\n\n  field :resolver_field, resolver: SomeTypeResolver\n\n  # In SomeTypeResolver\n\n  extras [:parent]\n  type SomeType, null: true\n  description 'My field description.'\n"
            },
            {
                "description": "Declare your field’s method in your Presenter class and have it accept the `parent` keyword argument. This argument contains the parent GraphQL context , so you have to access the parent object with `parent[:parent_object]` or whatever key you used in your `Resolver` :",
                "example": "  # in ChildPresenter\n  def my_computing_method(parent:)\n    # do something with `parent[:parent_object]` here\n  end\n\n  # In SomeTypeResolver\n\n  def resolve(parent:)\n    # ...\n  end\n",
                "appendix": "For an example of real-world use, check this MR that added\n \n scopedPath\n \n and\n \n scopedUrl\n \n to\n \n IterationPresenter"
            }
        ]
    },
    {
        "title": "Mutations",
        "belongs to": "Mutations",
        "cases": [
            {
                "description": "Mutations are used to change any stored values, or to trigger actions. In the same way a GET-request should not modify data, we cannot modify data in a regular GraphQL-query. We can however in a mutation."
            }
        ]
    },
    {
        "title": "Building Mutations",
        "belongs to": "Mutations/Building Mutations",
        "cases": [
            {
                "description": "Mutations are stored in `app/graphql/mutations` , ideally grouped per resources they are mutating, similar to our services. They should inherit `Mutations::BaseMutation` . The fields defined on the mutation are returned as the result of the mutation."
            }
        ]
    },
    {
        "title": "Update mutation granularity",
        "belongs to": "Mutations/Building Mutations/Update mutation granularity",
        "cases": [
            {
                "description": "The service-oriented architecture in GitLab means that most mutations call a Create, Delete, or Update service, for example `UpdateMergeRequestService` . For Update mutations, you might want to only update one aspect of an object, and thus only need a fine-grained mutation, for example `MergeRequest::SetDraft` .\nIt’s acceptable to have both fine-grained mutations and coarse-grained mutations, but be aware that too many fine-grained mutations can lead to organizational challenges in maintainability, code comprehensibility, and testing. Each mutation requires a new class, which can lead to technical debt. It also means the schema becomes very big, which can make it difficult for users to navigate our schema. As each new mutation also needs tests (including slower request integration tests), adding mutations slows down the test suite.\nTo minimize changes:\nUse existing mutations, such as `MergeRequest::Update` , when available. \nExpose existing services as a coarse-grained mutation.\nWhen a fine-grained mutation might be more appropriate:\nModifying a property that requires specific permissions or other specialized logic. \nExposing a state-machine-like transition (locking issues, merging MRs, closing epics, etc). \nAccepting nested properties (where we accept properties for a child object). \nThe semantics of the mutation can be expressed clearly and concisely.\nSee issue #233063 for further context."
            }
        ]
    },
    {
        "title": "Naming conventions",
        "belongs to": "Mutations/Building Mutations/Naming conventions",
        "cases": [
            {
                "description": "Each mutation must define a `graphql_name` , which is the name of the mutation in the GraphQL schema.\nExample:",
                "example": "class UserUpdateMutation < BaseMutation\n  graphql_name 'UserUpdate'\nend\n",
                "appendix": "Due to changes in the `1.13` version of the `graphql-ruby` gem, `graphql_name` should be the first line of the class to ensure that type names are generated correctly. The `Graphql::GraphqlNamePosition` cop enforces this. See issue #27536 for further context.\nOur GraphQL mutation names are historically inconsistent, but new mutation names should follow the convention `'{Resource}{Action}'` or `'{Resource}{Action}{Attribute}'` .\nMutations that create new resources should use the verb `Create` .\nExample:\n`CommitCreate`\nMutations that update data should use:\nThe verb `Update` . \nA domain-specific verb like `Set` , `Add` , or `Toggle` if more appropriate.\nExamples:\n`EpicTreeReorder` \n`IssueSetWeight` \n`IssueUpdate` \n`TodoMarkDone`\nMutations that remove data should use:\nThe verb `Delete` rather than `Destroy` . \nA domain-specific verb like `Remove` if more appropriate.\nExamples:\n`AwardEmojiRemove` \n`NoteDelete`\nIf you need advice for mutation naming, canvass the Slack `#graphql` channel for feedback."
            }
        ]
    },
    {
        "title": "Fields",
        "belongs to": "Mutations/Building Mutations/Fields",
        "cases": [
            {
                "description": "In the most common situations, a mutation would return 2 fields:\nThe resource being modified \nA list of errors explaining why the action could not be performed. If the mutation succeeded, this list would be empty.\nBy inheriting any new mutations from `Mutations::BaseMutation` the `errors` field is automatically added. A `clientMutationId` field is also added, this can be used by the client to identify the result of a single mutation when multiple are performed in a single request."
            }
        ]
    },
    {
        "title": "The resolve method",
        "belongs to": "Mutations/Building Mutations/The resolve method",
        "cases": [
            {
                "description": "Similar to writing resolvers , the `resolve` method of a mutation should aim to be a thin declarative wrapper around a service .\nThe `resolve` method receives the mutation’s arguments as keyword arguments. From here, we can call the service that modifies the resource.\nThe `resolve` method should then return a hash with the same field names as defined on the mutation including an `errors` array. For example, the `Mutations::MergeRequests::SetDraft` defines a `merge_request` field:",
                "example": "field :merge_request,\n      Types::MergeRequestType,\n      null: true,\n      description: \"The merge request after mutation.\"\n"
            },
            {
                "description": "This means that the hash returned from `resolve` in this mutation should look like this:",
                "example": "{\n  # The merge request modified, this will be wrapped in the type\n  # defined on the field\n  merge_request: merge_request,\n  # An array of strings if the mutation failed after authorization.\n  # The `errors_on_object` helper collects `errors.full_messages`\n  errors: errors_on_object(merge_request)\n}\n"
            }
        ]
    },
    {
        "title": "Mounting the mutation",
        "belongs to": "Mutations/Building Mutations/Mounting the mutation",
        "cases": [
            {
                "description": "To make the mutation available it must be defined on the mutation type that is stored in `graphql/types/mutation_type` . The `mount_mutation` helper method defines a field based on the GraphQL-name of the mutation:",
                "example": "module Types\n  class MutationType < BaseObject\n    graphql_name 'Mutation'\n\n    include Gitlab::Graphql::MountMutation\n\n    mount_mutation Mutations::MergeRequests::SetDraft\n  end\nend\n",
                "appendix": "Generates a field called `mergeRequestSetDraft` that `Mutations::MergeRequests::SetDraft` to be resolved."
            }
        ]
    },
    {
        "title": "Authorizing resources",
        "belongs to": "Mutations/Building Mutations/Authorizing resources",
        "cases": [
            {
                "description": "To authorize resources inside a mutation, we first provide the required abilities on the mutation like this:",
                "example": "module Mutations\n  module MergeRequests\n    class SetDraft < Base\n      graphql_name 'MergeRequestSetDraft'\n\n      authorize :update_merge_request\n    end\n  end\nend\n",
                "appendix": "We can then call `authorize!` in the `resolve` method, passing in the resource we want to validate the abilities for.\nAlternatively, we can add a `find_object` method that loads the object on the mutation. This would allow you to use the `authorized_find!` helper method.\nWhen a user is not allowed to perform the action, or an object is not found, we should raise a `Gitlab::Graphql::Errors::ResourceNotAvailable` by calling `raise_resource_not_available_error!` from in the `resolve` method."
            }
        ]
    },
    {
        "title": "Errors in mutations",
        "belongs to": "Mutations/Building Mutations/Errors in mutations",
        "cases": [
            {
                "description": "We encourage following the practice of errors as data for mutations, which distinguishes errors by who they are relevant to, defined by who can deal with them.\nKey points:\nAll mutation responses have an `errors` field. This should be populated on failure, and may be populated on success. \nConsider who needs to see the error: the user or the developer . \nClients should always request the `errors` field when performing mutations. \nErrors may be reported to users either at `$root.errors` (top-level error) or at `$root.data.mutationName.errors` (mutation errors). The location depends on what kind of error this is, and what information it holds. \nMutation fields must have\n \n null: true\nConsider an example mutation `doTheThing` that returns a response with two fields: `errors:[String]` , and `thing:ThingType` . The specific nature of the `thing` itself is irrelevant to these examples, as we are considering the errors.\nThe three states a mutation response can be in are:\nSuccess \nFailure (relevant to the user) \nFailure (irrelevant to the user)"
            }
        ]
    },
    {
        "title": "Success",
        "belongs to": "Mutations/Building Mutations/Errors in mutations/Success",
        "cases": [
            {
                "description": "In the happy path, errors may be returned, along with the anticipated payload, but if everything was successful, then `errors` should be an empty array, because there are no problems we need to inform the user of.",
                "example": "{\n  data: {\n    doTheThing: {\n      errors: [] // if successful, this array will generally be empty.\n      thing: { .. }\n    }\n  }\n}\n"
            }
        ]
    },
    {
        "title": "Failure (relevant to the user)",
        "belongs to": "Mutations/Building Mutations/Errors in mutations/Failure (relevant to the user)",
        "cases": [
            {
                "description": "An error that affects the user occurred. We refer to these as mutation errors .\nIn a create mutation there is typically no `thing` to return.\nIn an update mutation we return the current true state of `thing` . Developers may need to call `#reset` on the `thing` instance to ensure this happens.",
                "example": "{\n  data: {\n    doTheThing: {\n      errors: [\"you cannot touch the thing\"],\n      thing: { .. }\n    }\n  }\n}\n",
                "appendix": "Examples of this include:\nModel validation errors: the user may need to change the inputs. \nPermission errors: the user needs to know they cannot do this, they may need to request permission or sign in. \nProblems with the application state that prevent the user’s action (for example, merge conflicts or a locked resource).\nIdeally, we should prevent the user from getting this far, but if they do, they need to be told what is wrong, so they understand the reason for the failure and what they can do to achieve their intent. For example, they might only need to retry the request.\nIt is possible to return recoverable errors alongside mutation data. For example, if a user uploads 10 files and 3 of them fail and the rest succeed, the errors for the failures can be made available to the user, alongside the information about the successes."
            }
        ]
    },
    {
        "title": "Failure (irrelevant to the user)",
        "belongs to": "Mutations/Building Mutations/Errors in mutations/Failure (irrelevant to the user)",
        "cases": [
            {
                "description": "One or more non-recoverable errors can be returned at the top level . These are things over which the user has little to no control, and should mainly be system or programming problems, that a developer needs to know about. In this case there is no `data` :",
                "example": "{\n  errors: [\n    {\"message\": \"argument error: expected an integer, got null\"},\n  ]\n}\n",
                "appendix": "This results from raising an error during the mutation. In our implementation, the messages of argument errors and validation errors are returned to the client, and all other `StandardError` instances are caught, logged and presented to the client with the message set to `\"Internalservererror\"` . See GraphqlController for details.\nThese represent programming errors, such as:\nA GraphQL syntax error, where an `Int` was passed instead of a `String` , or a required argument was not present. \nErrors in our schema, such as being unable to provide a value for a non-nullable field. \nSystem errors: for example, a Git storage exception, or database unavailability.\nThe user should not be able to cause such errors in regular usage. This category of errors should be treated as internal, and not shown to the user in specific detail.\nWe need to inform the user when the mutation fails, but we do not need to tell them why, because they cannot have caused it, and nothing they can do fixes it, although we may offer to retry the mutation."
            }
        ]
    },
    {
        "title": "Categorizing errors",
        "belongs to": "Mutations/Building Mutations/Errors in mutations/Categorizing errors",
        "cases": [
            {
                "description": "When we write mutations, we need to be conscious about which of these two categories an error state falls into (and communicate about this with frontend developers to verify our assumptions). This means distinguishing the needs of the user from the needs of the client .\nNever catch an error unless the user needs to know about it.\nIf the user does need to know about it, communicate with frontend developers to make sure the error information we are passing back is relevant and serves a purpose.\nSee also the frontend GraphQL guide ."
            }
        ]
    },
    {
        "title": "Aliasing and deprecating mutations",
        "belongs to": "Mutations/Building Mutations/Errors in mutations/Aliasing and deprecating mutations",
        "cases": [
            {
                "description": "The `#mount_aliased_mutation` helper allows us to alias a mutation as another name in `MutationType` .\nFor example, to alias a mutation called `FooMutation` as `BarMutation` :",
                "example": "mount_aliased_mutation 'BarMutation', Mutations::FooMutation\n"
            },
            {
                "description": "This allows us to rename a mutation and continue to support the old name, when coupled with the deprecated argument.\nExample:",
                "example": "mount_aliased_mutation 'UpdateFoo',\n                        Mutations::Foo::Update,\n                        deprecated: { reason: 'Use fooUpdate', milestone: '13.2' }\n",
                "appendix": "Deprecated mutations should be added to `Types::DeprecatedMutations` and tested for in the unit test of `Types::MutationType` . The merge request !34798 can be referred to as an example of this, including the method of testing deprecated aliased mutations."
            }
        ]
    },
    {
        "title": "Deprecating EE mutations",
        "belongs to": "Mutations/Building Mutations/Errors in mutations/Aliasing and deprecating mutations/Deprecating EE mutations",
        "cases": [
            {
                "description": "EE mutations should follow the same process. For an example of the merge request process, read merge request !42588 ."
            }
        ]
    },
    {
        "title": "Subscriptions",
        "belongs to": "Subscriptions",
        "cases": [
            {
                "description": "We use subscriptions to push updates to clients. We use the Action Cable implementation to deliver the messages over websockets.\nWhen a client subscribes to a subscription, we store their query in-memory in Puma workers. Then when the subscription is triggered, the Puma workers execute the stored GraphQL queries and push the results to the clients.\nnote \nWe cannot test subscriptions using GraphiQL, because they require an Action Cable client, which GraphiQL does not support at the moment."
            }
        ]
    },
    {
        "title": "Building subscriptions",
        "belongs to": "Subscriptions/Building subscriptions",
        "cases": [
            {
                "description": "All fields under `Types::SubscriptionType` are subscriptions that clients can subscribe to. These fields require a subscription class, which is a descendant of `Subscriptions::BaseSubscription` and is stored under `app/graphql/subscriptions` .\nThe arguments required to subscribe and the fields that are returned are defined in the subscription class. Multiple fields can share the same subscription class if they have the same arguments and return the same fields.\nThis class runs during the initial subscription request and subsequent updates. You can read more about this in the GraphQL Ruby guides ."
            }
        ]
    },
    {
        "title": "Authorization",
        "belongs to": "Subscriptions/Authorization",
        "cases": [
            {
                "description": "You should implement the `#authorized?` method of the subscription class so that the initial subscription and subsequent updates are authorized.\nWhen a user is not authorized, you should call the `unauthorized!` helper so that execution is halted and the user is unsubscribed. Returning `false` results in redaction of the response, but we leak information that some updates are happening. This leakage is due to a bug in the GraphQL gem ."
            }
        ]
    },
    {
        "title": "Triggering subscriptions",
        "belongs to": "Subscriptions/Triggering subscriptions",
        "cases": [
            {
                "description": "Define a method under the `GraphqlTriggers` module to trigger a subscription. Do not call `GitlabSchema.subscriptions.trigger` directly in application code so that we have a single source of truth and we do not trigger a subscription with different arguments and objects."
            }
        ]
    },
    {
        "title": "Pagination implementation",
        "belongs to": "Pagination implementation",
        "cases": [
            {
                "description": "For more information, see GraphQL pagination ."
            }
        ]
    },
    {
        "title": "Arguments",
        "belongs to": "Arguments",
        "cases": [
            {
                "description": "Arguments for a resolver or mutation are defined using `argument` .\nExample:",
                "example": "argument :my_arg, GraphQL::Types::String,\n         required: true,\n         description: \"A description of the argument.\"\n"
            }
        ]
    },
    {
        "title": "Nullability",
        "belongs to": "Arguments/Nullability",
        "cases": [
            {
                "description": "Arguments can be marked as `required:true` which means the value must be present and not `null` . If a required argument’s value can be `null` , use the `required::nullable` declaration.\nExample:",
                "example": "argument :due_date,\n         Types::TimeType,\n         required: :nullable,\n         description: 'The desired due date for the issue. Due date is removed if null.'\n"
            },
            {
                "description": "In the above example, the `due_date` argument must be given, but unlike the GraphQL spec, the value can be `null` . This allows ‘unsetting’ the due date in a single mutation rather than creating a new mutation for removing the due date.",
                "example": "{ due_date: null } # => OK\n{ due_date: \"2025-01-10\" } # => OK\n{  } # => invalid (not given)\n"
            }
        ]
    },
    {
        "title": "Nullability and required: false",
        "belongs to": "Arguments/Nullability/Nullability and required: false",
        "cases": [
            {
                "description": "If an argument is marked `required:false` the client is permitted to send `null` as a value. Often this is undesirable.\nIf an argument is optional but `null` is not an allowed value, use validation to ensure that passing `null` returns an error:",
                "example": "argument :name, GraphQL::Types::String,\n         required: false,\n         validates: { allow_null: false }\n"
            },
            {
                "description": "Alternatively, if you wish to allow `null` when it is not an allowed value, you can replace it with a default value:",
                "example": "argument :name, GraphQL::Types::String,\n         required: false,\n         default_value: \"No Name Provided\",\n         replace_null_with_default: true\n",
                "appendix": "See Validation , Nullability and Default Values for more details."
            }
        ]
    },
    {
        "title": "Keywords",
        "belongs to": "Arguments/Nullability/Keywords",
        "cases": [
            {
                "description": "Each GraphQL `argument` defined is passed to the `#resolve` method of a mutation as keyword arguments.\nExample:",
                "example": "def resolve(my_arg:)\n  # Perform mutation ...\nend\n"
            }
        ]
    },
    {
        "title": "Input Types",
        "belongs to": "Arguments/Nullability/Input Types",
        "cases": [
            {
                "description": "`graphql-ruby` wraps up arguments into an input type .\nFor example, the mergeRequestSetDraft\n \n mutation defines these arguments (some through inheritance ):",
                "example": "argument :project_path, GraphQL::Types::ID,\n         required: true,\n         description: \"Project the merge request belongs to.\"\n\nargument :iid, GraphQL::Types::String,\n         required: true,\n         description: \"IID of the merge request.\"\n\nargument :draft,\n         GraphQL::Types::Boolean,\n         required: false,\n         description: <<~DESC\n           Whether or not to set the merge request as a draft.\n         DESC\n",
                "appendix": "These arguments automatically generate an input type called `MergeRequestSetDraftInput` with the 3 arguments we specified and the `clientMutationId` ."
            }
        ]
    },
    {
        "title": "Object identifier arguments",
        "belongs to": "Arguments/Nullability/Object identifier arguments",
        "cases": [
            {
                "description": "Arguments that identify an object should be:\nA full path or an IID if an object has either. \nThe object’s Global ID for all other objects. Never use plain database primary key IDs."
            }
        ]
    },
    {
        "title": "Full path object identifier arguments",
        "belongs to": "Arguments/Nullability/Object identifier arguments/Full path object identifier arguments",
        "cases": [
            {
                "description": "Historically we have been inconsistent with the naming of full path arguments, but prefer to name the argument:\n`project_path` for a project full path \n`group_path` for a group full path \n`namespace_path` for a namespace full path\nUsing an example from the ciJobTokenScopeRemoveProject\n \n mutation :",
                "example": "argument :project_path, GraphQL::Types::ID,\n         required: true,\n         description: 'Project the CI job token scope belongs to.'\n"
            }
        ]
    },
    {
        "title": "IID object identifier arguments",
        "belongs to": "Arguments/Nullability/Object identifier arguments/IID object identifier arguments",
        "cases": [
            {
                "description": "Use the `iid` of an object in combination with its parent `project_path` or `group_path` . For example:",
                "example": "argument :project_path, GraphQL::Types::ID,\n         required: true,\n         description: 'Project the issue belongs to.'\n\nargument :iid, GraphQL::Types::String,\n         required: true,\n         description: 'IID of the issue.'\n"
            }
        ]
    },
    {
        "title": "Global ID object identifier arguments",
        "belongs to": "Arguments/Nullability/Object identifier arguments/Global ID object identifier arguments",
        "cases": [
            {
                "description": "Using an example from the discussionToggleResolve\n \n mutation :",
                "example": "argument :id, Types::GlobalIDType[Discussion],\n         required: true,\n         description: 'Global ID of the discussion.'\n",
                "appendix": "See also Deprecate Global IDs ."
            }
        ]
    },
    {
        "title": "Sort arguments",
        "belongs to": "Arguments/Nullability/Object identifier arguments/Sort arguments",
        "cases": [
            {
                "description": "Sort arguments should use an enum type whenever possible to describe the set of available sorting values.\nThe enum can inherit from `Types::SortEnum` to inherit some common values.\nThe enum values should follow the format `{PROPERTY}_{DIRECTION}` . For example:",
                "example": "TITLE_ASC\n"
            },
            {
                "description": "Also see the description style guide for sort enums .\nExample from ContainerRepositoriesResolver :",
                "example": "# Types::ContainerRepositorySortEnum:\nmodule Types\n  class ContainerRepositorySortEnum < SortEnum\n    graphql_name 'ContainerRepositorySort'\n    description 'Values for sorting container repositories'\n\n    value 'NAME_ASC', 'Name by ascending order.', value: :name_asc\n    value 'NAME_DESC', 'Name by descending order.', value: :name_desc\n  end\nend\n\n# Resolvers::ContainerRepositoriesResolver:\nargument :sort, Types::ContainerRepositorySortEnum,\n          description: 'Sort container repositories by this criteria.',\n          required: false,\n          default_value: :created_desc\n"
            }
        ]
    },
    {
        "title": "GitLab custom scalars",
        "belongs to": "GitLab custom scalars",
        "cases": []
    },
    {
        "title": "Types::TimeType",
        "belongs to": "GitLab custom scalars/Types::TimeType",
        "cases": [
            {
                "description": "Types::TimeType must be used as the type for all fields and arguments that deal with Ruby `Time` and `DateTime` objects.\nThe type is a custom scalar that:\nConverts Ruby’s `Time` and `DateTime` objects into standardized ISO-8601 formatted strings, when used as the type for our GraphQL fields. \nConverts ISO-8601 formatted time strings into Ruby `Time` objects, when used as the type for our GraphQL arguments.\nThis allows our GraphQL API to have a standardized way that it presents time and handles time inputs.\nExample:",
                "example": "field :created_at, Types::TimeType, null: true, description: 'Timestamp of when the issue was created.'\n"
            }
        ]
    },
    {
        "title": "Testing",
        "belongs to": "Testing",
        "cases": [
            {
                "description": "For testing mutations and resolvers, consider the unit of test a full GraphQL request, not a call to a resolver. This allows us to avoid tight coupling to the framework because such coupling makes upgrades to dependencies much more difficult.\nYou should:\nPrefer request specs (either using the full API endpoint or going through `GitlabSchema.execute` ) to unit specs for resolvers and mutations. \nPrefer `GraphqlHelpers#execute_query` and `GraphqlHelpers#run_with_clean_state` to `GraphqlHelpers#resolve` and `GraphqlHelpers#resolve_field` .\nFor example:",
                "example": "# Good:\ngql_query = %q(some query text...)\npost_graphql(gql_query, current_user: current_user)\n# or:\nGitlabSchema.execute(gql_query, context: { current_user: current_user })\n\n# Deprecated: avoid\nresolve(described_class, obj: project, ctx: { current_user: current_user })\n"
            }
        ]
    },
    {
        "title": "Writing unit tests (deprecated)",
        "belongs to": "Testing/Writing unit tests (deprecated)",
        "cases": [
            {
                "description": "caution \nAvoid writing unit tests if the same thing can be tested with a full GraphQL request.\nBefore creating unit tests, review the following examples:\nspec/graphql/resolvers/users_resolver_spec.rb \nspec/graphql/mutations/issues/create_spec.rb"
            }
        ]
    },
    {
        "title": "Writing integration tests",
        "belongs to": "Testing/Writing integration tests",
        "cases": [
            {
                "description": "Integration tests check the full stack for a GraphQL query or mutation and are stored in `spec/requests/api/graphql` .\nFor speed, consider calling `GitlabSchema.execute` directly, or making use of smaller test schemas that only contain the types under test.\nHowever, full request integration tests that check if data is returned verify the following additional items:\nThe mutation is actually queryable in the schema (was mounted in `MutationType` ). \nThe data returned by a resolver or mutation correctly matches the return types of the fields and resolves without errors. \nThe arguments coerce correctly on input, and the fields serialize correctly on output.\nIntegration tests can also verify the following items, because they invoke the full stack:\nAn argument or scalar’s validations apply correctly. \nLogic in a resolver or mutation’s #ready?\n \n method applies correctly. \nAn argument’s\n \n default_value applies correctly. \nObjects resolve successfully, and there are no N+1 issues.\nWhen adding a query, you can use the `aworkinggraphqlquerythatreturnsdata` and `aworkinggraphqlquerythatreturnsnodata` shared examples to test if the query renders valid results.\nYou can construct a query including all available fields using the `GraphqlHelpers#all_graphql_fields_for` helper. This makes it more straightforward to add a test rendering all possible fields for a query.\nIf you’re adding a field to a query that supports pagination and sorting, visit Testing for details.\nTo test GraphQL mutation requests, `GraphqlHelpers` provides two helpers: `graphql_mutation` which takes the name of the mutation, and a hash with the input for the mutation. This returns a struct with a mutation query, and prepared variables.\nYou can then pass this struct to the `post_graphql_mutation` helper, that posts the request with the correct parameters, like a GraphQL client would do.\nTo access the response of a mutation, you can use the `graphql_mutation_response` helper.\nUsing these helpers, you can build specs like this:",
                "example": "let(:mutation) do\n  graphql_mutation(\n    :merge_request_set_wip,\n    project_path: 'gitlab-org/gitlab-foss',\n    iid: '1',\n    wip: true\n  )\nend\n\nit 'returns a successful response' do\n   post_graphql_mutation(mutation, current_user: user)\n\n   expect(response).to have_gitlab_http_status(:success)\n   expect(graphql_mutation_response(:merge_request_set_wip)['errors']).to be_empty\nend\n"
            }
        ]
    },
    {
        "title": "Testing tips and tricks",
        "belongs to": "Testing/Testing tips and tricks",
        "cases": [
            {
                "description": "Become familiar with the methods in the `GraphqlHelpers` support module. Many of these methods make writing GraphQL tests easier. \nUse traversal helpers like `GraphqlHelpers#graphql_data_at` and `GraphqlHelpers#graphql_dig_at` to access result fields. For example:",
                "example": "result = GitlabSchema.execute(query)\n\nmr_iid = graphql_dig_at(result.to_h, :data, :project, :merge_request, :iid)\n"
            },
            {
                "description": "Use `GraphqlHelpers#a_graphql_entity_for` to match against results. For example:",
                "example": "post_graphql(some_query)\n\n# checks that it is a hash containing { id => global_id_of(issue) }\nexpect(graphql_data_at(:project, :issues, :nodes))\n  .to contain_exactly(a_graphql_entity_for(issue))\n\n# Additional fields can be passed, either as names of methods, or with values\nexpect(graphql_data_at(:project, :issues, :nodes))\n  .to contain_exactly(a_graphql_entity_for(issue, :iid, :title, created_at: some_time))\n"
            },
            {
                "description": "Use `GraphqlHelpers#empty_schema` to create an empty schema, rather than creating one by hand. For example:",
                "example": "# good\nlet(:schema) { empty_schema }\n\n# bad\nlet(:query_type) { GraphQL::ObjectType.new }\nlet(:schema) { GraphQL::Schema.define(query: query_type, mutation: nil)}\n"
            },
            {
                "description": "Use `GraphqlHelpers#query_double(schema:nil)` of `double('query',schema:nil)` . For example:",
                "example": "# good\nlet(:query) { query_double(schema: GitlabSchema) }\n\n# bad\nlet(:query) { double('Query', schema: GitlabSchema) }\n"
            },
            {
                "description": "Avoid false positives: \nAuthenticating a user with the `current_user:` argument for `post_graphql` generates more queries on the first request than on subsequent requests on that same user. If you are testing for N+1 queries using QueryRecorder , use a different user for each request. \nThe below example shows how a test for avoiding N+1 queries should look:",
                "example": "RSpec.describe 'Query.project(fullPath).pipelines' do\n  include GraphqlHelpers\n\n  let(:project) { create(:project) }\n\n  let(:query) do\n    %(\n      {\n        project(fullPath: \"#{project.full_path}\") {\n          pipelines {\n            nodes {\n              id\n            }\n          }\n        }\n      }\n    )\n  end\n\n  it 'avoids N+1 queries' do\n    first_user = create(:user)\n    second_user = create(:user)\n    create(:ci_pipeline, project: project)\n\n    control_count = ActiveRecord::QueryRecorder.new do\n      post_graphql(query, current_user: first_user)\n    end\n\n    create(:ci_pipeline, project: project)\n\n    expect do\n      post_graphql(query, current_user: second_user)  # use a different user to avoid a false positive from authentication queries\n    end.not_to exceed_query_limit(control_count)\n  end\nend\n"
            },
            {
                "description": "Mimic the folder structure of `app/graphql/types` : \nFor example, tests for fields on `Types::Ci::PipelineType` in `app/graphql/types/ci/pipeline_type.rb` should be stored in `spec/requests/api/graphql/ci/pipeline_spec.rb` regardless of the query being used to fetch the pipeline data. \nWhen testing resolvers using `GraphqlHelpers#resolve` , arguments for the resolver can be handled two ways. \n95% of the resolver specs use arguments that are Ruby objects, as opposed to when using the GraphQL API only strings and integers are used. This works fine in most cases. \nIf your resolver takes arguments that use a `prepare` proc, such as a resolver that accepts time frame arguments ( `TimeFrameArguments` ), you must pass the `arg_style::internal_prepared` parameter into the `resolve` method. This tells the code to convert the arguments into strings and integers and pass them through regular argument handling, ensuring that the `prepare` proc is called correctly. For example in iterations_resolver_spec.rb :",
                "example": "def resolve_group_iterations(args = {}, obj = group, context = { current_user: current_user })\n  resolve(described_class, obj: obj, args: args, ctx: context, arg_style: :internal_prepared)\nend\n"
            },
            {
                "description": "One additional caveat is that if you are passing enums as a resolver argument, you must use the external representation of the enum, rather than the internal. For example:",
                "example": "# good\nresolve_group_iterations({ search: search, in: ['CADENCE_TITLE'] })\n\n# bad\nresolve_group_iterations({ search: search, in: [:cadence_title] })\n",
                "appendix": "The use of `:internal_prepared` was added as a bridge for the GraphQL gem upgrade. Testing resolvers directly will eventually be removed , and writing unit tests for resolvers/mutations is already deprecated"
            }
        ]
    },
    {
        "title": "Notes about Query flow and GraphQL infrastructure",
        "belongs to": "Notes about Query flow and GraphQL infrastructure",
        "cases": [
            {
                "description": "The GitLab GraphQL infrastructure can be found in `lib/gitlab/graphql` .\nInstrumentation is functionality that wraps around a query being executed. It is implemented as a module that uses the `Instrumentation` class.\nExample: `Present`",
                "example": "module Gitlab\n  module Graphql\n    module Present\n      #... some code above...\n\n      def self.use(schema_definition)\n        schema_definition.instrument(:field, ::Gitlab::Graphql::Present::Instrumentation.new)\n      end\n    end\n  end\nend\n",
                "appendix": "A Query Analyzer contains a series of callbacks to validate queries before they are executed. Each field can pass through the analyzer, and the final value is also available to you.\nMultiplex queries enable multiple queries to be sent in a single request. This reduces the number of requests sent to the server. (there are custom Multiplex Query Analyzers and Multiplex Instrumentation provided by GraphQL Ruby)."
            }
        ]
    },
    {
        "title": "Query limits",
        "belongs to": "Notes about Query flow and GraphQL infrastructure/Query limits",
        "cases": [
            {
                "description": "Queries and mutations are limited by depth, complexity, and recursion to protect server resources from overly ambitious or malicious queries. These values can be set as defaults and overridden in specific queries as needed. The complexity values can be set per object as well, and the final query complexity is evaluated based on how many objects are being returned. This can be used for objects that are expensive (such as requiring Gitaly calls).\nFor example, a conditional complexity method in a resolver:",
                "example": "def self.resolver_complexity(args, child_complexity:)\n  complexity = super\n  complexity += 2 if args[:labelName]\n\n  complexity\nend\n",
                "appendix": "More about complexity: GraphQL Ruby documentation ."
            }
        ]
    },
    {
        "title": "Documentation and schema",
        "belongs to": "Documentation and schema",
        "cases": [
            {
                "description": "Our schema is located at `app/graphql/gitlab_schema.rb` . See the schema reference for details.\nThis generated GraphQL documentation needs to be updated when the schema changes. For information on generating GraphQL documentation and schema files, see updating the schema documentation .\nTo help our readers, you should also add a new page to our GraphQL API documentation. For guidance, see the GraphQL API page."
            }
        ]
    },
    {
        "title": "Include a changelog entry",
        "belongs to": "Include a changelog entry",
        "cases": [
            {
                "description": "All client-facing changes must include a changelog entry ."
            }
        ]
    },
    {
        "title": "Laziness",
        "belongs to": "Laziness",
        "cases": [
            {
                "description": "One important technique unique to GraphQL for managing performance is using lazy values. Lazy values represent the promise of a result, allowing their action to be run later, which enables batching of queries in different parts of the query tree. The main example of lazy values in our code is the GraphQL BatchLoader .\nTo manage lazy values directly, read `Gitlab::Graphql::Lazy` , and in particular `Gitlab::Graphql::Laziness` . This contains `#force` and `#delay` , which help implement the basic operations of creation and elimination of laziness, where needed.\nFor dealing with lazy values without forcing them, use `Gitlab::Graphql::Lazy.with_value` ."
            }
        ]
    },
    {
        "title": "Privacy Preference Center",
        "belongs to": "Privacy Preference Center",
        "cases": []
    }
]